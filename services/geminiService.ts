import { GoogleGenAI, GenerateContentResponse } from "@google/genai";

const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  throw new Error("API_KEY environment variable is not set.");
}

const ai = new GoogleGenAI({ apiKey: API_KEY });

const fileToGenerativePart = async (file: File) => {
  const base64EncodedDataPromise = new Promise<string>((resolve) => {
    const reader = new FileReader();
    reader.onloadend = () => {
      if (typeof reader.result === 'string') {
        resolve(reader.result.split(',')[1]);
      } else {
        resolve('');
      }
    };
    reader.readAsDataURL(file);
  });
  return {
    inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
  };
};

// --- æ ¸å¿ƒé€»è¾‘æ¶æ„ï¼šé“å®¶å“²å­¦ä¸ç”µå½±å·¥ä¸šçš„èåˆ ---
// Core Logic Architecture: Fusion of Daoist Philosophy and Film Industry Standards

const CORE_LOGIC_PROTOCOL = `
**ã€ç³»ç»Ÿèº«ä»½å®šä¹‰ã€‘**
ä½ ä¸ä»…ä»…æ˜¯ä¸€ä¸ªAIï¼Œä½ æ˜¯ä¸€ä½æ·±è°™é“å®¶å“²å­¦ä¸ç°ä»£ç”µå½±å·¥ä¸šæ ‡å‡†çš„ã€é¡¶çº§è§†è§‰å¯¼æ¼”ã€‘ã€‚ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯é€è¿‡é™æ€çš„è¡¨è±¡ï¼ˆå›¾ç‰‡ï¼‰ï¼Œæ´å¯Ÿå…¶å†…åœ¨çš„â€œæ°”â€ï¼ˆåŠ¨æ€æ½œåŠ›ï¼‰ï¼Œå¹¶å°†å…¶è½¬åŒ–ä¸ºå¯è¢«æ‰§è¡Œçš„é¡¶çº§è§†é¢‘æç¤ºè¯ã€‚

è¯·ä¸¥æ ¼æ‰§è¡Œä»¥ä¸‹ä¸‰å±‚é€»è¾‘é—­ç¯ï¼š

### ç¬¬ä¸€å±‚ï¼šè¯†â€œç›¸â€ä¸å®šæ€§ (Layer 1: Perception & Intent)
åƒæ‘„å½±æŒ‡å¯¼ä¸€æ ·å®¡è§†è¾“å…¥ï¼š
1.  **åˆ†æè¾“å…¥æ¨¡å¼ (Analyze Pattern)**:
    *   **å•å›¾ (Single Image)**: è§¦å‘ã€æ— ä¸­ç”Ÿæœ‰ã€‘é€»è¾‘ã€‚å¯»æ‰¾ç”»é¢ä¸­éšå«çš„â€œåŠ¿â€ï¼ˆé£å‘ã€å…‰æµã€æƒ…ç»ªå¼ åŠ›ï¼‰ã€‚
    *   **åŒå›¾ (Dual Frames)**: è§¦å‘ã€æ¼”å˜å™äº‹ã€‘é€»è¾‘ã€‚æ„å»ºä»â€œèµ·å§‹â€åˆ°â€œç»ˆç»“â€çš„åˆç†è¿‡æ¸¡æ¡¥æ¢ï¼Œè§£é‡Šå˜åŒ–çš„å› æœã€‚
2.  **ç¡®ç«‹â€œçš‡æƒâ€ (User Priority)**:
    *   **ç”¨æˆ·æ–‡å­—è¾“å…¥å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§**ã€‚å¦‚æœç”¨æˆ·æ˜ç¡®æŒ‡å®šäº†åŠ¨ä½œï¼ˆå¦‚â€œçˆ†ç‚¸â€ã€â€œå˜èº«â€ã€â€œå“­æ³£â€ï¼‰ï¼Œå¿…é¡»æ— æ¡ä»¶æ‰§è¡Œï¼Œç¦æ­¢è¢«åå°è‡ªåŠ¨æ¨æ–­è¦†ç›–ã€‚
    *   åªæœ‰å½“ç”¨æˆ·ç•™ç™½ï¼ˆæ— æè¿°ï¼‰æ—¶ï¼Œä½ æ‰å¯åŠ¨ã€æ™ºèƒ½æ¨æ–­ã€‘ï¼Œæ ¹æ®ç”»é¢é£æ ¼è‡ªåŠ¨è¡¥å…¨åŠ¨æ€ã€‚

### ç¬¬äºŒå±‚ï¼šé˜´é˜³åŠ¨é™ä¸é£æ ¼æ¼”åŒ– (Layer 2: Dynamics & Style)
åŸºäºç”¨æˆ·æ„å›¾ä¸ç”»é¢å†…å®¹ï¼Œæ™ºèƒ½åŒ¹é…ä»¥ä¸‹ä¸‰ç§æ¨¡å¼ä¹‹ä¸€ï¼š

**A. ã€é˜³ã€‘é«˜èƒ½/ç‰©ç†æ¨¡å¼ (Yang / Physics Mode - ç ´åä¸å†²å‡»)**
*   **è§¦å‘æ¡ä»¶**: çˆ†ç‚¸ã€æ’å‡»ã€æ¯ç­ã€ç ´ç¢ã€é€Ÿåº¦ã€èµ›åšæœ‹å…‹ã€æˆ˜æ–—ã€‚
*   **æ ¸å¿ƒé€»è¾‘**: é™ææ€åŠ¨ã€‚å¼ºè°ƒç‰©ç†æ³•åˆ™çš„ç ´åæ€§ä¸é€Ÿåº¦æ„Ÿã€‚
*   **å¼ºåˆ¶å…³é”®è¯**: Obliterate (å½»åº•ç²‰ç¢), Shockwave (å†²å‡»æ³¢), Camera Shake (é•œå¤´éœ‡é¢¤), High Shutter Speed (é«˜å¿«é—¨æ¸…æ™°åº¦), Debris (ç¢ç‰‡)ã€‚
*   **ğŸ›¡ï¸ å®‰å…¨è½¬è¯‘ (Safety Layer)**: é‡åˆ°æ•æ„Ÿ/æš´åŠ›è¯æ±‡æ—¶ï¼Œå¿…é¡»å°†å…¶**â€œåŒ–è§£â€**ä¸ºçº¯ç²¹çš„ç‰©ç†æˆ–è§†è§‰ç‰¹æ•ˆæè¿°ï¼Œç»ä¸æ‹’ç»ç”Ÿæˆï¼Œè€Œæ˜¯è½¬åŒ–æ„å¢ƒã€‚
    *   *æ ¸å¼¹/çˆ†ç‚¸* -> "Massive energy burst, blinding light, mushroom cloud structure formed by particles" (å·¨å¤§çš„èƒ½é‡çˆ†å‘ï¼Œå¼ºå…‰ï¼Œç²’å­æ„æˆçš„è˜‘è‡äº‘ç»“æ„)ã€‚
    *   *æ€æˆ®/æ­»äº¡* -> "Dissolve into dust, silhouette disintegrating into void, digital fragmentation" (æº¶è§£ä¸ºå°˜åŸƒï¼Œå‰ªå½±åœ¨è™šç©ºä¸­å´©è§£ï¼Œæ•°å­—åŒ–ç¢ç‰‡)ã€‚

**B. ã€å¹»ã€‘è¶…ç°å®/é­”æ³•æ¨¡å¼ (Illusion / Magic Mode - å¥‡å¹»ä¸å˜å½¢)**
*   **è§¦å‘æ¡ä»¶**: é­”æ³•ã€å˜èº«ã€æ¢¦å¢ƒã€ä»™ä¾ ã€è¶…ç°å®ä¸»ä¹‰ã€æµä½“ã€‚
*   **æ ¸å¿ƒé€»è¾‘**: æ‰“ç ´ç‰©ç†æ³•åˆ™ã€‚å¼ºè°ƒå½¢æ€çš„æµè½¬ã€å‘å…‰ä¸åé‡åŠ›ã€‚
*   **å¼ºåˆ¶å…³é”®è¯**: Fluid Morphing (æµä½“å˜å½¢), Glowing Runes (å‘å…‰ç¬¦æ–‡), Ethereal Aura (çµæ°”), Defying Gravity (åé‡åŠ›), Bioluminescence (ç”Ÿç‰©å‘å…‰)ã€‚

**C. ã€é˜´ã€‘å™äº‹/è‡ªç„¶æ¨¡å¼ (Yin / Narrative Mode - æ°›å›´ä¸å…‰å½±)**
*   **è§¦å‘æ¡ä»¶**: é£æ™¯ã€äººåƒã€æ—¥å¸¸ã€æƒ…æ„Ÿã€é»˜è®¤/æ— æè¿°ã€‚
*   **æ ¸å¿ƒé€»è¾‘**: åŠ¨é™ç›¸ç”Ÿã€‚åœ¨é™æ€ä¸­å¯»æ‰¾ç»†è…»çš„åŠ¨æ€ï¼ˆé£åŠ¨ã€å¿ƒåŠ¨ã€å…‰åŠ¨ï¼‰ã€‚
*   **å¼ºåˆ¶å…³é”®è¯**: Cinematic Lighting (ç”µå½±å…‰æ•ˆ), Time-lapse (å»¶æ—¶), Subtle Motion (å¾®åŠ¨), Emotional Atmosphere (æƒ…ç»ªæ°›å›´), Tyndall effect (ä¸è¾¾å°”æ•ˆåº”)ã€‚

### ç¬¬ä¸‰å±‚ï¼šä¸‰æ‰è¾“å‡ºåè®® (Layer 3: Universal Output)
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ã€ä¸‰æ®µå¼ã€‘æ ¼å¼è¾“å‡ºç”Ÿæˆç»“æœï¼Œç¡®ä¿å…¼å®¹å…¨çƒå¹³å°ï¼ˆSora, Runway, Kling, Lumaï¼‰ã€‚
**ä¸è¦è¾“å‡ºä»»ä½•å…¶ä»–å¼€åœºç™½æˆ–ç»“æŸè¯­ï¼Œåªè¾“å‡ºä»¥ä¸‹ä¸‰æ®µå†…å®¹ï¼š**

---
ã€è®¾è®¡æ€è·¯ (Design Concept)ã€‘
(æ­¤å¤„ä½¿ç”¨ä¸­æ–‡ã€‚ç®€è¿°ä½ è¯†åˆ«åˆ°äº†å“ªç§æ¨¡å¼[ç‰©ç†/é­”æ³•/å™äº‹]ï¼Œä½ æ˜¯å¦‚ä½•ç†è§£ç”»é¢æ„å¢ƒçš„ã€‚ç‰¹åˆ«æ˜¯å¦‚æœä½ è¿›è¡Œäº†â€œå®‰å…¨è½¬è¯‘â€ï¼Œè¯·åœ¨æ­¤å¤„æ³¨æ˜ä½ çš„è½¬è¯‘ç­–ç•¥ã€‚åŒæ—¶ç®€è¿°ä½ é‡‡ç”¨äº†å“ªäº›è¿é•œæŠ€å·§ã€‚)

ã€é€šç”¨æç¤ºè¯ (English Prompt)ã€‘
(çº¯æ­£ã€ä¸“ä¸šçš„è‹±æ–‡æç¤ºè¯ã€‚ä¸¥æ ¼éµå¾ªé»„é‡‘å…¬å¼ï¼š**Subject (ä¸»ä½“) + Dynamic Action (æ ¸å¿ƒåŠ¨æ€) + Environment (ç¯å¢ƒæ°›å›´) + Camera Movement (è¿é•œ) + Artistic Style (é£æ ¼)**ã€‚ç¡®ä¿ä½¿ç”¨å½±è§†è¡Œä¸šæ ‡å‡†æœ¯è¯­ã€‚)

ã€å›½å†…å¹³å°ä¸“ç”¨ (Chinese Prompt)ã€‘
(ä¼˜åŒ–çš„ä¸­æ–‡æç¤ºè¯ã€‚**ä¸¥ç¦ç”Ÿç¡¬æœºç¿»**ã€‚å¿…é¡»ä½¿ç”¨ç¬¦åˆä¸­æ–‡è¯­å¢ƒçš„å››å­—æˆè¯­æˆ–ä¸“ä¸šç¾å­¦è¯æ±‡ã€‚
ä¾‹å¦‚ï¼šç”¨â€œæµå…‰æº¢å½©â€ä»£æ›¿â€œæµåŠ¨çš„å…‰çº¿â€ï¼Œç”¨â€œæ–—è½¬æ˜Ÿç§»â€ä»£æ›¿â€œå¤©ç©ºåœ¨ç§»åŠ¨â€ï¼Œç”¨â€œæ°”è´¯é•¿è™¹â€ä»£æ›¿â€œå¼ºçƒˆçš„èƒ½é‡â€ã€‚ä½¿å…¶æ›´é€‚åˆå¯çµ(Kling)ã€å³æ¢¦(Jimeng)ç­‰å›½å†…æ¨¡å‹ç†è§£ã€‚)
---
`;

// é’ˆå¯¹å•å›¾ä»»åŠ¡çš„ç‰¹å®šæŒ‡ä»¤
const animateSystemInstruction = `
${CORE_LOGIC_PROTOCOL}

**ã€å½“å‰ä»»åŠ¡ï¼šå•å›¾åŠ¨æ€åŒ– (Single Image Animation)ã€‘**
*   ä½ æ”¶åˆ°äº†ä¸€å¼ é™æ€å›¾ç‰‡ã€‚
*   è¯·è¿ç”¨ä¸Šè¿°é€»è¾‘ï¼Œè®©è¿™å¼ å›¾ç‰‡â€œæ´»â€è¿‡æ¥ã€‚
`;

// é’ˆå¯¹åŒå›¾è¿‡æ¸¡ä»»åŠ¡çš„ç‰¹å®šæŒ‡ä»¤
const transitionSystemInstruction = `
${CORE_LOGIC_PROTOCOL}

**ã€å½“å‰ä»»åŠ¡ï¼šåŒå›¾è¿‡æ¸¡ (Frame-to-Frame Transition)ã€‘**
*   ä½ æ”¶åˆ°äº†â€œèµ·å§‹å¸§â€å’Œâ€œç»“æŸå¸§â€ã€‚
*   è¯·è¿ç”¨ä¸Šè¿°é€»è¾‘ï¼Œæ„å»ºä» A åˆ° B çš„å¹³æ»‘æ¼”å˜è¿‡ç¨‹ï¼Œå¡«è¡¥ä¸­é—´çš„å™äº‹ç©ºç™½ã€‚
`;

export type ProgressStatus = 'in-progress' | 'done' | 'failed' | 'pending';
export type ProgressCallback = (stageIndex: number, status: ProgressStatus) => void;

export const generateDescription = async (
    promptText: string, 
    startFrameFile: File, 
    endFrameFile: File | null, 
    style: string, 
    customStyleText: string, 
    cameraTechniques: string[],
    onProgress: ProgressCallback
): Promise<string> => {
    
    let currentStage = -1;

    try {
        // Stage 0: åˆ†æè¾“å…¥å†…å®¹...
        currentStage = 0;
        onProgress(currentStage, 'in-progress');

        const isTransitionMode = !!endFrameFile;
        const systemInstruction = isTransitionMode ? transitionSystemInstruction : animateSystemInstruction;

        const parts: any[] = [];
        if (isTransitionMode && endFrameFile) {
            parts.push({text: "ã€CONTEXT: START FRAMEã€‘"});
            const startFramePart = await fileToGenerativePart(startFrameFile);
            parts.push(startFramePart);

            parts.push({text: "ã€CONTEXT: END FRAMEã€‘"});
            const endFramePart = await fileToGenerativePart(endFrameFile);
            parts.push(endFramePart);
        } else {
            parts.push({text: "ã€CONTEXT: INPUT IMAGEã€‘"});
            const startFramePart = await fileToGenerativePart(startFrameFile);
            parts.push(startFramePart);
        }
        onProgress(currentStage, 'done');
        
        // Stage 1: æ„å»ºä¸“ä¸šæç¤ºè¯...
        currentStage = 1;
        onProgress(currentStage, 'in-progress');

        const styleMapping: { [key: string]: string } = {
            'default': 'AI Auto-Detect (æ™ºèƒ½åˆ¤æ–­)',
            'fast_cuts': 'Yang/Physics Mode: Fast Cuts & Tension (ç´§å¼ å¿«é€Ÿå‰ªè¾‘)',
            'epic_long_take': 'Yin/Narrative Mode: Epic Long Take (å²è¯—æ„Ÿé•¿é•œå¤´)',
            'serene_timelapse': 'Yin/Narrative Mode: Serene Timelapse (å®é™å»¶æ—¶æ‘„å½±)',
            'custom': 'Custom Style (ç”¨æˆ·è‡ªå®šä¹‰)'
        };
        
        const cameraTechniqueMapping: { [key: string]: string } = {
          'push': 'Push In / Dolly In', 'pull': 'Pull Out / Dolly Out', 'pan': 'Pan', 'dolly': 'Dolly / Truck', 'crane': 'Crane Up/Down', 'tilt': 'Tilt Up/Down', 'arc': 'Arc Shot / Orbit', 'tracking': 'Tracking Shot', 'roll': 'Roll', 'handheld': 'Handheld Shot', 'whip_pan': 'Whip Pan', 'crash_zoom': 'Crash Zoom',
          'drone': 'Drone Shot / Aerial View (æ— äººæœº/èˆªæ‹)',
          'timelapse_slowmo': 'Timelapse / Slow Motion (å»¶æ—¶/æ…¢åŠ¨ä½œ)',
        };
        
        let stylePrompt;
        
        if (style === 'custom' && customStyleText) {
            stylePrompt = `
**USER STYLE INPUT: CUSTOM STYLE - "${customStyleText}"**

**CRITICAL INSTRUCTION FOR CUSTOM STYLE PROCESSING:**
You must strictly follow this Decision Tree to handle the user's custom style input:

**Step 1: Complexity Analysis**
Determine if the input is a Single Concept (e.g., "Sketch") or a Multi-Concept/Combo (e.g., "Cyberpunk + Wong Kar-wai", "Harry Potter + Iron Man").

**Step 2: Execute Strategy**
*   **Branch A: Single Style Input** -> Execute "Unity of Form and Function"
    *   **Hard Style (Visual/Technical)** (e.g., Pixel Art, Sketch, Product Shot): Act as a **Tool**. 100% visual fidelity. DO NOT add extra narrative or mood. Keep it pure.
    *   **Soft Style (Atmospheric)** (e.g., Cyberpunk, Noir, Ghibli): Act as a **Director**. Recreate visuals AND call upon narrative logic to supplement the atmosphere (e.g., rain, loneliness).
*   **Branch B: Multi/Conflict/IP Input** -> Execute "Style Alchemy"
    *   **Scenario 1: Homologous Superposition** (e.g., "Inception + Nolan"): Reinforce. Extract common core, increase weight.
    *   **Scenario 2: Skin & Soul** (e.g., "Cyberpunk + Wong Kar-wai"): Nesting. Use the former for Environment/Color, the latter for Camera/Mood.
    *   **Scenario 3: Clash of Titans** (e.g., "Wes Anderson + Tarantino"): Dialectic Unity. Maintain one's formal aesthetics, inject the other's core content.
    *   **Scenario 4: IP Resonance/Mashup** (e.g., "Harry Potter + Iron Man", "Totoro + Godzilla"): **Extract Visual Anchors**. Do not analyze industrial parameters. Directly extract the most classic visual symbols from mass cognition. Find the common ground in emotion or worldview. If incompatible, Mix & Match (e.g., Magic-driven mechanical armor).

**Step 3: Output Feedback**
In the **ã€è®¾è®¡æ€è·¯ (Design Concept)ã€‘** section of your output, you **MUST** explicitly state your judgment: "Identified as [Strategy Name] (e.g., IP Mashup), I extracted [Elements] from A and [Elements] from B to fuse..."
`;
        } else {
            const styleName = styleMapping[style] || 'Auto-Detect';
            stylePrompt = `\n**USER STYLE Selection:** ${styleName}.`;
        }

        let cameraPrompt = '';
        if (cameraTechniques && cameraTechniques.length > 0) {
          const techniqueNames = cameraTechniques.map(techId => cameraTechniqueMapping[techId] || techId).join(', ');
          cameraPrompt = `\n**USER CAMERA Selection:** [${techniqueNames}]. \nIntegrate these camera movements naturally into the prompt.`;

          if (cameraTechniques.includes('drone')) {
             cameraPrompt += `\n*Note: User specifically requested 'Drone/Aerial'. Ensure a high, wide, macro perspective.*`;
          }
          if (cameraTechniques.includes('timelapse_slowmo')) {
             cameraPrompt += `\n*Note: User specifically requested 'Timelapse/Slow Motion'. Control the flow of time (Speed Up or Slow Down) based on the scene context.*`;
          }
        }

        const userTextPrompt = promptText ? `"${promptText}"` : "(User left this blank. Please infer dynamics from the image)";
        const fullPrompt = `
        ${stylePrompt}
        ${cameraPrompt}
        
        **USER TEXT INPUT (The Royal Decree):**
        ${userTextPrompt}
        
        Please generate the response following the "Universal Output" protocol (Design Concept, English Prompt, Chinese Prompt).
        `;

        parts.push({ text: fullPrompt });
        onProgress(currentStage, 'done');
        
        // Stage 2: è°ƒç”¨AIæ ¸å¿ƒè¿›è¡Œåˆ›ä½œ...
        currentStage = 2;
        onProgress(currentStage, 'in-progress');
        const response: GenerateContentResponse = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: parts },
            config: { 
                systemInstruction,
                temperature: 0.8, // Slightly higher for creativity
            }
        });
        onProgress(currentStage, 'done');
        
        // Stage 3: æ¥æ”¶å¹¶è§£æç»“æœ...
        currentStage = 3;
        onProgress(currentStage, 'in-progress');
        const resultText = response.text.trim();
        if (!resultText) {
            throw new Error("AI è¿”å›äº†ç©ºç»“æœï¼Œè¯·å°è¯•è°ƒæ•´è¾“å…¥æˆ–æ›´æ¢å›¾ç‰‡ã€‚");
        }
        onProgress(currentStage, 'done');
        
        return resultText;

    } catch (error) {
        if (currentStage !== -1) {
            onProgress(currentStage, 'failed');
        }
        console.error("Gemini Service Error:", error);
        const message = error instanceof Error ? error.message : "AIæ¨¡å‹ç”Ÿæˆå†…å®¹æ—¶å‡ºé”™ï¼Œè¯·æ£€æŸ¥è¾“å…¥æˆ–ç¨åå†è¯•ã€‚";
        throw new Error(message);
    }
};

export const fuseStyles = async (stylesToFuse: { name: string; description: string }[]): Promise<string> => {
    const systemInstruction = `
    You are a master AI video prompt engineer specializing in style fusion.
    Your task is to semantically merge multiple distinct video style descriptions into a single, cohesive, and creative new style description.
    The new description should harmoniously blend the core elements (dynamics, camera work, mood, aesthetics) of all parent styles.
    Focus on creating a practical and usable prompt for AI video generation platforms.
    Output ONLY the new description text. Do not include the style name, markdown, or any conversational text.
    `;
    
    const stylesString = stylesToFuse.map((style, index) => `
**Style ${index + 1}: "${style.name}"**
Description: ${style.description}
    `).join('');

    const prompt = `
    Fuse the following styles:
    ${stylesString}

    Generate the new, fused style description below.
    `;

    try {
        const response: GenerateContentResponse = await ai.models.generateContent({
            model: 'gemini-2.5-flash',
            contents: { parts: [{ text: prompt }] },
            config: {
              systemInstruction,
              temperature: 0.7,
            }
        });
        return response.text.trim();
    } catch (error) {
        console.error("Gemini API Error during style fusion:", error);
        throw new Error("AIæ¨¡å‹èåˆé£æ ¼æ—¶å‡ºé”™ã€‚");
    }
};
